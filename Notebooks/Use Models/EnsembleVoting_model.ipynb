{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# make a prediction with a stacking ensemble\n",
    "# compare ensemble to each baseline classifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "import np as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "\n",
    "# get the dataset\n",
    "def get_dataset():\n",
    "\n",
    "    #==============================================\n",
    "    # LOAD DATASET                                |\n",
    "    #==============================================\n",
    "\n",
    "    global X_train, X_test, y_train, y_test\n",
    "    df = pd.read_csv ('C:/Users/inmar/OneDrive/Documentos/Unesp/Doutorado/stacking/Models creation/Single Project Training/Single-model/Commons_compress/dataset.csv')\n",
    "    df.head()\n",
    "\n",
    "    #==============================================\n",
    "    # SPLIT DATASET                               |\n",
    "    #==============================================\n",
    "    X = df.iloc[:, 0:6]\n",
    "    y = df.iloc[:, 6:7]\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "    for train_index, test_index in kfold.split(X, y):\n",
    "        # select rows and columns\n",
    "        X_train, X_test = X.iloc[train_index, :], X.iloc[test_index, :]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        # summarize train and test composition\n",
    "        train_0, train_1 = y_train['buggy'].value_counts()[0], y_train['buggy'].value_counts()[1]\n",
    "        test_0, test_1 = y_test['buggy'].value_counts()[0], y_test['buggy'].value_counts()[1]\n",
    "        print('>Train: 0=%d, 1=%d, Test: 0=%d, 1=%d' % (train_0, train_1, test_0, test_1))\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Train: 0=6691, 1=404, Test: 0=744, 1=45\n",
      ">Train: 0=6691, 1=404, Test: 0=744, 1=45\n",
      ">Train: 0=6691, 1=404, Test: 0=744, 1=45\n",
      ">Train: 0=6691, 1=404, Test: 0=744, 1=45\n",
      ">Train: 0=6691, 1=405, Test: 0=744, 1=44\n",
      ">Train: 0=6692, 1=404, Test: 0=743, 1=45\n",
      ">Train: 0=6692, 1=404, Test: 0=743, 1=45\n",
      ">Train: 0=6692, 1=404, Test: 0=743, 1=45\n",
      ">Train: 0=6692, 1=404, Test: 0=743, 1=45\n",
      ">Train: 0=6692, 1=404, Test: 0=743, 1=45\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'fit_time': array([1.66606927, 1.4778831 , 1.67619228, 1.7235837 , 1.57557726,\n        1.64377546, 1.59041214, 1.8066659 , 1.60743666, 1.51054311]),\n 'score_time': array([0.11853552, 0.12755203, 0.13951874, 0.13403726, 0.14853072,\n        0.1452961 , 0.15061879, 0.1320169 , 0.11559129, 0.12365437]),\n 'estimator': [VotingClassifier(estimators=[('lr',\n                                LogisticRegression(max_iter=1000,\n                                                   random_state=42)),\n                               ('lda',\n                                LinearDiscriminantAnalysis(shrinkage='auto',\n                                                           solver='lsqr')),\n                               ('rf', RandomForestClassifier(random_state=42)),\n                               ('bayes', GaussianNB()),\n                               ('svm', SVC(probability=True, random_state=42)),\n                               ('cart',\n                                DecisionTreeClassifier(criterion='entropy',\n                                                       max_depth=5,\n                                                       min_samples_split=10)),\n                               ('knn',\n                                KNeighborsClassifier(algorithm='kd_tree',\n                                                     weights='distance'))],\n                   voting='soft'),\n  VotingClassifier(estimators=[('lr',\n                                LogisticRegression(max_iter=1000,\n                                                   random_state=42)),\n                               ('lda',\n                                LinearDiscriminantAnalysis(shrinkage='auto',\n                                                           solver='lsqr')),\n                               ('rf', RandomForestClassifier(random_state=42)),\n                               ('bayes', GaussianNB()),\n                               ('svm', SVC(probability=True, random_state=42)),\n                               ('cart',\n                                DecisionTreeClassifier(criterion='entropy',\n                                                       max_depth=5,\n                                                       min_samples_split=10)),\n                               ('knn',\n                                KNeighborsClassifier(algorithm='kd_tree',\n                                                     weights='distance'))],\n                   voting='soft'),\n  VotingClassifier(estimators=[('lr',\n                                LogisticRegression(max_iter=1000,\n                                                   random_state=42)),\n                               ('lda',\n                                LinearDiscriminantAnalysis(shrinkage='auto',\n                                                           solver='lsqr')),\n                               ('rf', RandomForestClassifier(random_state=42)),\n                               ('bayes', GaussianNB()),\n                               ('svm', SVC(probability=True, random_state=42)),\n                               ('cart',\n                                DecisionTreeClassifier(criterion='entropy',\n                                                       max_depth=5,\n                                                       min_samples_split=10)),\n                               ('knn',\n                                KNeighborsClassifier(algorithm='kd_tree',\n                                                     weights='distance'))],\n                   voting='soft'),\n  VotingClassifier(estimators=[('lr',\n                                LogisticRegression(max_iter=1000,\n                                                   random_state=42)),\n                               ('lda',\n                                LinearDiscriminantAnalysis(shrinkage='auto',\n                                                           solver='lsqr')),\n                               ('rf', RandomForestClassifier(random_state=42)),\n                               ('bayes', GaussianNB()),\n                               ('svm', SVC(probability=True, random_state=42)),\n                               ('cart',\n                                DecisionTreeClassifier(criterion='entropy',\n                                                       max_depth=5,\n                                                       min_samples_split=10)),\n                               ('knn',\n                                KNeighborsClassifier(algorithm='kd_tree',\n                                                     weights='distance'))],\n                   voting='soft'),\n  VotingClassifier(estimators=[('lr',\n                                LogisticRegression(max_iter=1000,\n                                                   random_state=42)),\n                               ('lda',\n                                LinearDiscriminantAnalysis(shrinkage='auto',\n                                                           solver='lsqr')),\n                               ('rf', RandomForestClassifier(random_state=42)),\n                               ('bayes', GaussianNB()),\n                               ('svm', SVC(probability=True, random_state=42)),\n                               ('cart',\n                                DecisionTreeClassifier(criterion='entropy',\n                                                       max_depth=5,\n                                                       min_samples_split=10)),\n                               ('knn',\n                                KNeighborsClassifier(algorithm='kd_tree',\n                                                     weights='distance'))],\n                   voting='soft'),\n  VotingClassifier(estimators=[('lr',\n                                LogisticRegression(max_iter=1000,\n                                                   random_state=42)),\n                               ('lda',\n                                LinearDiscriminantAnalysis(shrinkage='auto',\n                                                           solver='lsqr')),\n                               ('rf', RandomForestClassifier(random_state=42)),\n                               ('bayes', GaussianNB()),\n                               ('svm', SVC(probability=True, random_state=42)),\n                               ('cart',\n                                DecisionTreeClassifier(criterion='entropy',\n                                                       max_depth=5,\n                                                       min_samples_split=10)),\n                               ('knn',\n                                KNeighborsClassifier(algorithm='kd_tree',\n                                                     weights='distance'))],\n                   voting='soft'),\n  VotingClassifier(estimators=[('lr',\n                                LogisticRegression(max_iter=1000,\n                                                   random_state=42)),\n                               ('lda',\n                                LinearDiscriminantAnalysis(shrinkage='auto',\n                                                           solver='lsqr')),\n                               ('rf', RandomForestClassifier(random_state=42)),\n                               ('bayes', GaussianNB()),\n                               ('svm', SVC(probability=True, random_state=42)),\n                               ('cart',\n                                DecisionTreeClassifier(criterion='entropy',\n                                                       max_depth=5,\n                                                       min_samples_split=10)),\n                               ('knn',\n                                KNeighborsClassifier(algorithm='kd_tree',\n                                                     weights='distance'))],\n                   voting='soft'),\n  VotingClassifier(estimators=[('lr',\n                                LogisticRegression(max_iter=1000,\n                                                   random_state=42)),\n                               ('lda',\n                                LinearDiscriminantAnalysis(shrinkage='auto',\n                                                           solver='lsqr')),\n                               ('rf', RandomForestClassifier(random_state=42)),\n                               ('bayes', GaussianNB()),\n                               ('svm', SVC(probability=True, random_state=42)),\n                               ('cart',\n                                DecisionTreeClassifier(criterion='entropy',\n                                                       max_depth=5,\n                                                       min_samples_split=10)),\n                               ('knn',\n                                KNeighborsClassifier(algorithm='kd_tree',\n                                                     weights='distance'))],\n                   voting='soft'),\n  VotingClassifier(estimators=[('lr',\n                                LogisticRegression(max_iter=1000,\n                                                   random_state=42)),\n                               ('lda',\n                                LinearDiscriminantAnalysis(shrinkage='auto',\n                                                           solver='lsqr')),\n                               ('rf', RandomForestClassifier(random_state=42)),\n                               ('bayes', GaussianNB()),\n                               ('svm', SVC(probability=True, random_state=42)),\n                               ('cart',\n                                DecisionTreeClassifier(criterion='entropy',\n                                                       max_depth=5,\n                                                       min_samples_split=10)),\n                               ('knn',\n                                KNeighborsClassifier(algorithm='kd_tree',\n                                                     weights='distance'))],\n                   voting='soft'),\n  VotingClassifier(estimators=[('lr',\n                                LogisticRegression(max_iter=1000,\n                                                   random_state=42)),\n                               ('lda',\n                                LinearDiscriminantAnalysis(shrinkage='auto',\n                                                           solver='lsqr')),\n                               ('rf', RandomForestClassifier(random_state=42)),\n                               ('bayes', GaussianNB()),\n                               ('svm', SVC(probability=True, random_state=42)),\n                               ('cart',\n                                DecisionTreeClassifier(criterion='entropy',\n                                                       max_depth=5,\n                                                       min_samples_split=10)),\n                               ('knn',\n                                KNeighborsClassifier(algorithm='kd_tree',\n                                                     weights='distance'))],\n                   voting='soft')],\n 'test_accuracy': array([0.94366197, 0.94366197, 0.94225352, 0.94225352, 0.94225352,\n        0.94225352, 0.94358251, 0.94358251, 0.94358251, 0.94358251]),\n 'test_precision': array([0.94683595, 0.94683595, 0.94558818, 0.94558818, 0.94558818,\n        0.94558818, 0.94676544, 0.94676544, 0.94676544, 0.94676544]),\n 'test_recall': array([0.94366197, 0.94366197, 0.94225352, 0.94225352, 0.94225352,\n        0.94225352, 0.94358251, 0.94358251, 0.94358251, 0.94358251]),\n 'test_f1': array([0.91630945, 0.91630945, 0.91423873, 0.91423873, 0.91423873,\n        0.91423873, 0.9161926 , 0.9161926 , 0.9161926 , 0.9161926 ]),\n 'test_roc_auc': array([0.8666791 , 0.67876866, 0.64690656, 0.62953443, 0.58365234,\n        0.75438405, 0.84753363, 0.86883408, 0.7387145 , 0.60254111]),\n 'test_log_loss': array([-0.20915752, -0.24364723, -0.24481796, -0.23294514, -0.24872526,\n        -0.20422504, -0.18454102, -0.19418328, -0.21161565, -0.22929881])}"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import make_scorer, recall_score, precision_score, f1_score, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = get_dataset()\n",
    "y_train_test_1d = np.array(y_train).ravel()\n",
    "\n",
    "scoring = {'accuracy': 'accuracy',\n",
    "           'precision': make_scorer(precision_score, average='weighted', zero_division=1),\n",
    "           'recall': make_scorer(recall_score, average='weighted'),\n",
    "           'f1': make_scorer(f1_score, average='weighted'),\n",
    "           'roc_auc': make_scorer(roc_auc_score, needs_proba=True, multi_class='ovr'),\n",
    "           'log_loss': 'neg_log_loss',\n",
    "           }\n",
    "\n",
    "level0 = list()\n",
    "level0.append(('lr', LogisticRegression(max_iter=1000, random_state=42)))\n",
    "level0.append(('lda', LinearDiscriminantAnalysis(solver='lsqr', shrinkage='auto')))\n",
    "level0.append(('rf', RandomForestClassifier(n_estimators=100, random_state=42)))\n",
    "level0.append(('bayes', GaussianNB()))\n",
    "level0.append(('svm', SVC(probability=True, random_state=42)))\n",
    "level0.append(('cart', DecisionTreeClassifier(max_depth=5, min_samples_split=10, criterion='entropy')))\n",
    "level0.append(('knn', KNeighborsClassifier(n_neighbors=5, weights='distance', algorithm='kd_tree')))\n",
    "\n",
    "# Create the voting classifier\n",
    "vc = VotingClassifier(estimators=level0, voting='soft')\n",
    "\n",
    "cv_results = cross_validate(vc, X_train, y_train_test_1d, cv=10, scoring=scoring, return_estimator=True)\n",
    "cv_results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision 0.9463086373057704\n",
      "recall 0.9430668070482131\n",
      "accuracy 0.9430668070482131\n",
      "F1 0.9154344218767234\n",
      "roc auc 0.7217548457537316\n",
      "log loss -0.2203156898818409\n"
     ]
    }
   ],
   "source": [
    "print('precision', cv_results['test_precision'].mean())\n",
    "print('recall', cv_results['test_recall'].mean())\n",
    "print('accuracy', cv_results['test_accuracy'].mean())\n",
    "print('F1', cv_results['test_f1'].mean())\n",
    "print('roc auc', cv_results['test_roc_auc'].mean())\n",
    "print('log loss', cv_results['test_log_loss'].mean())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "      number_of_authors     age  number_unique_changes  size  lines_added  \\\n19                    1       0                      1   120          119   \n26                    2  124257                      2    69           14   \n34                    1  137253                      2   425           14   \n42                    1   18829                      3   473            8   \n53                    2  526177                      3   117            1   \n...                 ...     ...                    ...   ...          ...   \n7817                  6  938425                      8    57            0   \n7835                 20   11036                    213  1581            0   \n7841                  8  119496                     27   102            0   \n7861                  5  253330                     11    48            0   \n7883                 17   18938                    143  1485           19   \n\n      lines_deleted  \n19                0  \n26               59  \n34               59  \n42                1  \n53                1  \n...             ...  \n7817              1  \n7835              1  \n7841              1  \n7861              1  \n7883             14  \n\n[788 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>number_of_authors</th>\n      <th>age</th>\n      <th>number_unique_changes</th>\n      <th>size</th>\n      <th>lines_added</th>\n      <th>lines_deleted</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>19</th>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>120</td>\n      <td>119</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>2</td>\n      <td>124257</td>\n      <td>2</td>\n      <td>69</td>\n      <td>14</td>\n      <td>59</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>1</td>\n      <td>137253</td>\n      <td>2</td>\n      <td>425</td>\n      <td>14</td>\n      <td>59</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>1</td>\n      <td>18829</td>\n      <td>3</td>\n      <td>473</td>\n      <td>8</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>2</td>\n      <td>526177</td>\n      <td>3</td>\n      <td>117</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7817</th>\n      <td>6</td>\n      <td>938425</td>\n      <td>8</td>\n      <td>57</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7835</th>\n      <td>20</td>\n      <td>11036</td>\n      <td>213</td>\n      <td>1581</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7841</th>\n      <td>8</td>\n      <td>119496</td>\n      <td>27</td>\n      <td>102</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7861</th>\n      <td>5</td>\n      <td>253330</td>\n      <td>11</td>\n      <td>48</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7883</th>\n      <td>17</td>\n      <td>18938</td>\n      <td>143</td>\n      <td>1485</td>\n      <td>19</td>\n      <td>14</td>\n    </tr>\n  </tbody>\n</table>\n<p>788 rows Ã— 6 columns</p>\n</div>"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "result_proba = cv_results['estimator'][0].predict_proba(X_test.iloc[:1])\n",
    "for i in range(1, len(cv_results['estimator'])):\n",
    "    result_proba = np.add(result_proba, cv_results['estimator'][i].predict_proba(X_test))\n",
    "\n",
    "result_proba = result_proba/10\n",
    "print(np.array2string(result_proba, formatter={'float_kind':lambda x: \"%.3f\" % x}))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming y_test contains the actual labels of the test set\n",
    "y_pred = (result_proba[:, 1] > 0.5).astype(int)\n",
    "y_pred\n",
    "\n",
    "# auc_score = roc_auc_score(y_test, result_proba[:, 1])\n",
    "# accuracy = (y_test == y_pred).mean()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "['cv_results.pkl']"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(cv_results, 'cv_results.pkl')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
