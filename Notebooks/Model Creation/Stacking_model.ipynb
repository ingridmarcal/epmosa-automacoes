{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-08-02T00:32:16.320660Z",
     "start_time": "2023-08-02T00:32:16.320209Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "# make a prediction with a stacking ensemble\n",
    "# compare ensemble to each baseline classifier\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import column_or_1d\n",
    "\n",
    "# get a stacking ensemble of models\n",
    "def get_stacking():\n",
    "    # define the base models\n",
    "    level0 = list()\n",
    "    level0.append(('lr', LogisticRegression(max_iter=1000)))\n",
    "    level0.append(('lda', LinearDiscriminantAnalysis()))\n",
    "    level0.append(('bayes', GaussianNB()))\n",
    "    level0.append(('svm', SVC()))\n",
    "    level0.append(('knn', KNeighborsClassifier()))\n",
    "    level0.append(('rf', RandomForestClassifier()))\n",
    "\n",
    "\n",
    "    # define meta learner model\n",
    "    level1 = DecisionTreeClassifier()\n",
    "    # define the stacking ensemble | cv = cross-validation\n",
    "    model = StackingClassifier(estimators=level0, final_estimator=level1, cv=5)\n",
    "    return model\n",
    "\n",
    "# evaluate a give model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=5, random_state=1)\n",
    "    scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "    return scores\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-02T00:32:17.580479Z",
     "start_time": "2023-08-02T00:32:17.577953Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import np as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import column_or_1d\n",
    "\n",
    "\n",
    "# get the dataset\n",
    "def get_stratified_dataset():\n",
    "\n",
    "    #==============================================\n",
    "    # LOAD DATASET                                |\n",
    "    #==============================================\n",
    "\n",
    "    df = pd.read_csv ('/Users/imarcal/Library/CloudStorage/OneDrive-Pessoal/Documentos/Unesp/Doutorado/stacking/Models creation/Single Project Training/Single-model/Commons_cli_ok/dataset.csv')\n",
    "    df.head()\n",
    "\n",
    "    #==============================================\n",
    "    # SPLIT DATASET                               |\n",
    "    #==============================================\n",
    "    X = df.iloc[:, 0:6]\n",
    "    y = df.iloc[:, 6:7]\n",
    "\n",
    "    # Feature Scaling for input features.\n",
    "    scaler = preprocessing.MinMaxScaler()\n",
    "    x_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "    for train_index, test_index in kfold.split(X, y):\n",
    "        # select rows and columns\n",
    "        x_train, x_test = x_scaled[train_index], x_scaled[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "        \n",
    "        # summarize train and test composition\n",
    "        train_0, train_1 = y_train['buggy'].value_counts()[0], y_train['buggy'].value_counts()[1]\n",
    "        test_0, test_1 = y_test['buggy'].value_counts()[0], y_test['buggy'].value_counts()[1]\n",
    "        print('>Train: 0=%d, 1=%d, Test: 0=%d, 1=%d' % (train_0, train_1, test_0, test_1))\n",
    "\n",
    "    return x_train, x_test, y_train, y_test"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-02T00:33:40.862232Z",
     "start_time": "2023-08-02T00:33:40.861387Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">Train: 0=1334, 1=59, Test: 0=149, 1=6\n",
      ">Train: 0=1334, 1=59, Test: 0=149, 1=6\n",
      ">Train: 0=1334, 1=59, Test: 0=149, 1=6\n",
      ">Train: 0=1335, 1=58, Test: 0=148, 1=7\n",
      ">Train: 0=1335, 1=58, Test: 0=148, 1=7\n",
      ">Train: 0=1335, 1=58, Test: 0=148, 1=7\n",
      ">Train: 0=1335, 1=58, Test: 0=148, 1=7\n",
      ">Train: 0=1335, 1=58, Test: 0=148, 1=7\n",
      ">Train: 0=1335, 1=59, Test: 0=148, 1=6\n",
      ">Train: 0=1335, 1=59, Test: 0=148, 1=6\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'fit_time': array([0.65830803, 0.445889  , 0.43300295, 0.43548703, 0.42700124,\n        0.42948294, 0.43109417, 0.43076181, 0.48580813, 0.42917585]),\n 'score_time': array([0.01229906, 0.00936198, 0.00932479, 0.00910997, 0.00932193,\n        0.00922394, 0.00907278, 0.00917006, 0.00908303, 0.00910211]),\n 'estimator': [StackingClassifier(cv=5,\n                     estimators=[('lr', LogisticRegression(max_iter=1000)),\n                                 ('lda', LinearDiscriminantAnalysis()),\n                                 ('bayes', GaussianNB()), ('svm', SVC()),\n                                 ('knn', KNeighborsClassifier()),\n                                 ('rf', RandomForestClassifier())],\n                     final_estimator=DecisionTreeClassifier()),\n  StackingClassifier(cv=5,\n                     estimators=[('lr', LogisticRegression(max_iter=1000)),\n                                 ('lda', LinearDiscriminantAnalysis()),\n                                 ('bayes', GaussianNB()), ('svm', SVC()),\n                                 ('knn', KNeighborsClassifier()),\n                                 ('rf', RandomForestClassifier())],\n                     final_estimator=DecisionTreeClassifier()),\n  StackingClassifier(cv=5,\n                     estimators=[('lr', LogisticRegression(max_iter=1000)),\n                                 ('lda', LinearDiscriminantAnalysis()),\n                                 ('bayes', GaussianNB()), ('svm', SVC()),\n                                 ('knn', KNeighborsClassifier()),\n                                 ('rf', RandomForestClassifier())],\n                     final_estimator=DecisionTreeClassifier()),\n  StackingClassifier(cv=5,\n                     estimators=[('lr', LogisticRegression(max_iter=1000)),\n                                 ('lda', LinearDiscriminantAnalysis()),\n                                 ('bayes', GaussianNB()), ('svm', SVC()),\n                                 ('knn', KNeighborsClassifier()),\n                                 ('rf', RandomForestClassifier())],\n                     final_estimator=DecisionTreeClassifier()),\n  StackingClassifier(cv=5,\n                     estimators=[('lr', LogisticRegression(max_iter=1000)),\n                                 ('lda', LinearDiscriminantAnalysis()),\n                                 ('bayes', GaussianNB()), ('svm', SVC()),\n                                 ('knn', KNeighborsClassifier()),\n                                 ('rf', RandomForestClassifier())],\n                     final_estimator=DecisionTreeClassifier()),\n  StackingClassifier(cv=5,\n                     estimators=[('lr', LogisticRegression(max_iter=1000)),\n                                 ('lda', LinearDiscriminantAnalysis()),\n                                 ('bayes', GaussianNB()), ('svm', SVC()),\n                                 ('knn', KNeighborsClassifier()),\n                                 ('rf', RandomForestClassifier())],\n                     final_estimator=DecisionTreeClassifier()),\n  StackingClassifier(cv=5,\n                     estimators=[('lr', LogisticRegression(max_iter=1000)),\n                                 ('lda', LinearDiscriminantAnalysis()),\n                                 ('bayes', GaussianNB()), ('svm', SVC()),\n                                 ('knn', KNeighborsClassifier()),\n                                 ('rf', RandomForestClassifier())],\n                     final_estimator=DecisionTreeClassifier()),\n  StackingClassifier(cv=5,\n                     estimators=[('lr', LogisticRegression(max_iter=1000)),\n                                 ('lda', LinearDiscriminantAnalysis()),\n                                 ('bayes', GaussianNB()), ('svm', SVC()),\n                                 ('knn', KNeighborsClassifier()),\n                                 ('rf', RandomForestClassifier())],\n                     final_estimator=DecisionTreeClassifier()),\n  StackingClassifier(cv=5,\n                     estimators=[('lr', LogisticRegression(max_iter=1000)),\n                                 ('lda', LinearDiscriminantAnalysis()),\n                                 ('bayes', GaussianNB()), ('svm', SVC()),\n                                 ('knn', KNeighborsClassifier()),\n                                 ('rf', RandomForestClassifier())],\n                     final_estimator=DecisionTreeClassifier()),\n  StackingClassifier(cv=5,\n                     estimators=[('lr', LogisticRegression(max_iter=1000)),\n                                 ('lda', LinearDiscriminantAnalysis()),\n                                 ('bayes', GaussianNB()), ('svm', SVC()),\n                                 ('knn', KNeighborsClassifier()),\n                                 ('rf', RandomForestClassifier())],\n                     final_estimator=DecisionTreeClassifier())],\n 'test_accuracy': array([0.91428571, 0.98571429, 0.92857143, 0.95      , 0.9352518 ,\n        0.96402878, 0.8705036 , 0.98561151, 0.97841727, 0.98561151]),\n 'test_precision': array([0.95419501, 0.98571429, 0.92857143, 0.94592593, 0.95987396,\n        0.95746932, 0.9216444 , 0.98561151, 0.97889336, 0.98582467]),\n 'test_recall': array([0.91428571, 0.98571429, 0.92857143, 0.95      , 0.9352518 ,\n        0.96402878, 0.8705036 , 0.98561151, 0.97841727, 0.98561151]),\n 'test_f1': array([0.93010989, 0.98571429, 0.92857143, 0.94782021, 0.94542769,\n        0.95823416, 0.89439518, 0.98561151, 0.97494049, 0.98422635]),\n 'test_roc_auc': array([0.7960199 , 0.91293532, 0.56467662, 0.65547264, 0.7738806 ,\n        0.66290727, 0.53446115, 0.91290727, 0.75      , 0.83333333]),\n 'test_log_loss': array([-3.089456  , -0.51490933, -2.57454667, -1.80218267, -2.33376173,\n        -1.29653429, -4.66752346, -0.51861372, -0.77792058, -0.51861372])}"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import make_scorer, precision_score, recall_score, average_precision_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "model = get_stacking()\n",
    "\n",
    "X_train_test, X_gtest, y_train_test, y_gtest = get_stratified_dataset()\n",
    "y_train_test_1d = np.array(y_train_test).ravel()\n",
    "\n",
    "scoring = {'accuracy': 'accuracy',\n",
    "           'precision': make_scorer(precision_score, average='weighted', zero_division=1),\n",
    "           'recall': make_scorer(recall_score, average='weighted'),\n",
    "           'f1': make_scorer(f1_score, average='weighted'),\n",
    "           'roc_auc': make_scorer(roc_auc_score, needs_proba=True, multi_class='ovr'),\n",
    "           'log_loss': 'neg_log_loss'\n",
    "           }\n",
    "\n",
    "cv_results = cross_validate(model, X_train_test, y_train_test_1d, cv=10, scoring=scoring, return_estimator=True)\n",
    "cv_results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-02T00:33:46.591177Z",
     "start_time": "2023-08-02T00:33:41.846983Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision 0.9603723870564342\n",
      "recall 0.9497995889003082\n",
      "accuracy 0.9497995889003082\n",
      "F1 0.9535051194648304\n",
      "roc auc 0.7396594097183257\n",
      "log loss -1.8094062176684762\n"
     ]
    }
   ],
   "source": [
    "print('precision', cv_results['test_precision'].mean())\n",
    "print('recall', cv_results['test_recall'].mean())\n",
    "print('accuracy', cv_results['test_accuracy'].mean())\n",
    "print('F1', cv_results['test_f1'].mean())\n",
    "print('roc auc', cv_results['test_roc_auc'].mean())\n",
    "print('log loss', cv_results['test_log_loss'].mean())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-02T00:34:01.118502Z",
     "start_time": "2023-08-02T00:34:01.097100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9610389610389609"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gtest_score = []\n",
    "for i in range(len(cv_results['estimator'])):\n",
    "    gtest_score.append(cv_results['estimator'][i].score(X_gtest, y_gtest))\n",
    "\n",
    "sum(gtest_score) / len(gtest_score)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-02T00:34:16.160449Z",
     "start_time": "2023-08-02T00:34:16.094888Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'iloc'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[25], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[0;32m----> 3\u001B[0m result_proba \u001B[38;5;241m=\u001B[39m cv_results[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mestimator\u001B[39m\u001B[38;5;124m'\u001B[39m][\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mpredict_proba(X_gtest\u001B[38;5;241m.\u001B[39miloc[:\u001B[38;5;241m1\u001B[39m])\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;28mlen\u001B[39m(cv_results[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mestimator\u001B[39m\u001B[38;5;124m'\u001B[39m])):\n\u001B[1;32m      5\u001B[0m     result_proba \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39madd(result_proba, cv_results[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mestimator\u001B[39m\u001B[38;5;124m'\u001B[39m][i]\u001B[38;5;241m.\u001B[39mpredict_proba(X_gtest))\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'numpy.ndarray' object has no attribute 'iloc'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "result_proba = cv_results['estimator'][0].predict_proba(X_gtest.iloc[:1])\n",
    "for i in range(1, len(cv_results['estimator'])):\n",
    "    result_proba = np.add(result_proba, cv_results['estimator'][i].predict_proba(X_gtest))\n",
    "\n",
    "result_proba = result_proba/10\n",
    "print(np.array2string(result_proba, formatter={'float_kind':lambda x: \"%.3f\" % x}))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-02T00:34:20.294324Z",
     "start_time": "2023-08-02T00:34:20.283285Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
